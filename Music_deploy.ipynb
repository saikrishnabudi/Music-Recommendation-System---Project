{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f34f309",
   "metadata": {
    "id": "7f34f309"
   },
   "source": [
    "Importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4aab2",
   "metadata": {
    "id": "ddf4aab2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0621af",
   "metadata": {
    "id": "1b0621af"
   },
   "source": [
    "Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f2565",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842
    },
    "id": "f20f2565",
    "outputId": "698f3aea-f1d9-4944-ad0e-63dc02c32934"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\suhas\\OneDrive\\Documents\\universal_top_spotify_songs.csv\",encoding=\"unicode_escape\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6594bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise import dump\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Create a Surprise dataset\n",
    "reader = Reader(rating_scale=(0, 1000))\n",
    "data = Dataset.load_from_df(df[['name', 'artists', 'popularity']], reader)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a collaborative filtering model (using SVD as an example)\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f'Model RMSE: {rmse}')\n",
    "\n",
    "# Save the model\n",
    "model_filename = 'collaborative_model.joblib'\n",
    "dump.dump(model_filename, algo=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from surprise import dump, Dataset, Reader\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model\n",
    "model_filename = 'collaborative_model.joblib'\n",
    "model = dump.load(model_filename)[1]\n",
    "\n",
    "# Sample dataset (replace this with your actual dataset)\n",
    "df = pd.DataFrame({\n",
    "    'song_id': ['Cruel Summer', 'Lovin On Me', 'My Love Mine All Mine', 'Si No Est√°s', 'LALA',\n",
    "                'Rockin\\' Around The Christmas Tree', 'Seven (feat. Latto) (Explicit Ver.)',\n",
    "                'Standing Next to You', 'Strangers'],\n",
    "    'user_id': ['user1'] * 9,  # Replace with your actual user IDs\n",
    "    'danceability': [0.8, 0.6, 0.9, 0.7, 0.5, 0.8, 0.6, 0.7, 0.9]  # Replace with your actual danceability values\n",
    "})\n",
    "\n",
    "# Streamlit app header\n",
    "st.title('Music Recommendation App')\n",
    "\n",
    "# Input form to get user preferences\n",
    "danceability = st.slider('Danceability', 0.0, 1.0, 0.5)\n",
    "energy = st.slider('Energy', 0.0, 1.0, 0.5)\n",
    "loudness = st.slider('Loudness', -20.0, 0.0, -10.0)\n",
    "\n",
    "# Button to trigger recommendations\n",
    "if st.button('Get Recommendations'):\n",
    "    # User preferences\n",
    "    user_input = {'user_id': 'user1', 'danceability': danceability, 'energy': energy, 'loudness': loudness}\n",
    "\n",
    "    # Convert the user preferences to a Surprise Dataset\n",
    "    reader = Reader(rating_scale=(0, 1))  # Update rating scale based on your dataset\n",
    "    data = Dataset.load_from_df(df[['user_id', 'song_id', 'danceability']], reader)\n",
    "\n",
    "    # Build the training set\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(trainset)\n",
    "\n",
    "    # Use the test method to generate predictions for all songs\n",
    "    predictions = [model.predict(user_input['user_id'], song_id, user_input['danceability']) for song_id in df['song_id']]\n",
    "\n",
    "    # Get the recommended song with the highest predicted rating\n",
    "    top_recommendation = max(predictions, key=lambda x: x.est)\n",
    "\n",
    "    # Display the recommended song\n",
    "    st.success(f\"Recommended Song: {top_recommendation.iid} with Predicted Rating: {top_recommendation.est}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
